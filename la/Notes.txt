

cut_missing, and vacuum extension to 3d, axis is keep not drop (?)
	e.g.  vaccuum, remove a row 
	indxb = isfinite(x).any(1).any(1) # is 1d boolean for not all nan, i.e. keep if true
	idx = np.nonzero(idx)  # integer index
	newx = x[idxb]
	newlabel = label.deepcopy()
	newlabel[axis] = label[idx]
	
	
convert nd (n>2) to 2d (function array2table)
	rollaxis for cross-section/columns (axis 2) to front or end
	reshape 
	loop labels to create combined labels of rows
	reverse/inverse operation
	useful also for using methods and functions that work only for 2d
	
sector/group functions axis argument ?

integer overflow possible problems - promote to float
    * larry.sum uses np.nansum
      >>> np.nansum([1,2,3])
	  6
	* other cases - not checked

which dtypes should be allowed for a larry ?
    * float
    * object for sector names
    * integers
    * strings ?

ranking functions
    * more flexibility axis, 3d ? 
    * meaning of 3d lastrank is not clear (maybe better with nd2table)
    * ranking_norm, ranking : for 1d the default changes 
      (matrix with 1 row axis=0, is different from 1d array with axis=0)
      newr = ranking_norm(x[0,:])
      oldr = la.afunc.ranking_norm(x[0,:], axis=1)

sorting of labels
	* alignment sorts labels
	* orientation for time for lag

add diff with same pattern as lag, (np.diff)

is frequent use of np.where necessary (hard to read ?)

optimization: (would need profiling for actual usage)
	what's the common use, data preparation or temporary storage during
		data analysis? 
	moving functions with convolve
	np.bincount is only 1d, speed depends on relative shape, long versus wide 
	dictionary (pandas) versus list access (larry) 
		(fast individual access versus fast slicing)
	list of numpy (objects) arrays instead of list of lists ? searchsorted ?
	    (I never really used object arrays, and lists have nice methods)
	possible to maintain dictionary as secondary indexing
	    small slow down in creation and changing, faster for index access by label 
	    unclear: fast subset selection of keys during slicing
	    maybe not worth it ?
	bottleneck seems to be alignment, e.g. for binary elementwise operations
	fast path through alignment check for already aligned larries


extension:
	nan filling by interpolation (guess not)
	statistics ? (pandas, statsmodels)
	general time filters ?
	how is time handled? not in larry
	nan versus masked arrays, nan only work with floats, (nan value for integers ?)
